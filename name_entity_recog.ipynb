{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1048575, 4)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"data/ner_dataset.csv\",encoding = \"ISO-8859-1\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    with open(file_path,\"r\") as file:\n",
    "        data=[ line.strip() for line in file.readlines()] \n",
    "    return data\n",
    "train_sentence=load_data('data/large/train/sentences.txt')\n",
    "train_labels=load_data('data/large/train/labels.txt')\n",
    "\n",
    "val_sentence=load_data('data/large/val/sentences.txt')\n",
    "val_labels=load_data('data/large/val/labels.txt')\n",
    "test_sentence=load_data('data/large/test/sentences.txt')\n",
    "test_labels=load_data('data/large/test/labels.txt')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<unk>': 1,\n",
       " 'O': 2,\n",
       " 'B-geo': 3,\n",
       " 'B-gpe': 4,\n",
       " 'B-per': 5,\n",
       " 'I-geo': 6,\n",
       " 'B-org': 7,\n",
       " 'I-org': 8,\n",
       " 'B-tim': 9,\n",
       " 'B-art': 10,\n",
       " 'I-art': 11,\n",
       " 'I-per': 12,\n",
       " 'I-gpe': 13,\n",
       " 'I-tim': 14,\n",
       " 'B-nat': 15,\n",
       " 'B-eve': 16,\n",
       " 'I-eve': 17,\n",
       " 'I-nat': 18}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_vocab(sentences):\n",
    "    vocab={}\n",
    "    vocab[\"<unk>\"]=1\n",
    "    i=2\n",
    "    for sentence in sentences:\n",
    "        sentence=sentence.strip().split()\n",
    "        for word in sentence:\n",
    "            if word not in vocab.keys():\n",
    "                vocab[word]=i\n",
    "                i+=1\n",
    "    return vocab\n",
    "\n",
    "vocab=create_vocab(train_sentence)\n",
    "label_vocab=create_vocab(train_labels)\n",
    "label_vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def id_to_tag(vocab):\n",
    "    tag_map={}\n",
    "    for i,tag in enumerate(vocab.keys()):\n",
    "        tag_map[tag]=i+1\n",
    "    return tag_map\n",
    "tag_map=id_to_tag(label_vocab)\n",
    "tag_map[\"<unk>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorized_sentence(vocab,sentences):\n",
    "    vectorized_sentences=[]\n",
    "    max_len=0\n",
    "    for i,sentence in enumerate(sentences):\n",
    "        sentence=sentence.strip().split()\n",
    "        max_len=np.maximum(max_len,len(sentence))\n",
    "        vectorized=[vocab.get(word,1) for word in sentence]\n",
    "        vectorized_sentences.append(torch.tensor(vectorized))\n",
    "    return vectorized_sentences,max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,max_len1=vectorized_sentence(vocab,train_sentence)\n",
    "test_data,max_len2=vectorized_sentence(vocab,test_sentence)\n",
    "train_label_data,_=vectorized_sentence(label_vocab,train_labels)\n",
    "test_label_data,_=vectorized_sentence(label_vocab,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len=0\n",
    "max_len=np.maximum(max_len,max_len1)\n",
    "max_len=np.maximum(max_len,max_len2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "len_train=len(train_data)\n",
    "data_for_padding=train_data+test_data\n",
    "data=pad_sequence(data_for_padding,padding_value=0,batch_first=True)\n",
    "X_train=data[:len_train]\n",
    "X_test=data[len_train:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_padding2=train_label_data+test_label_data\n",
    "data1=pad_sequence(data_for_padding2,padding_value=0,batch_first=True)\n",
    "y_train=data1[:len_train]\n",
    "y_test=data1[len_train:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=torch.utils.data.TensorDataset(X_train,y_train)\n",
    "test_dataset=torch.utils.data.TensorDataset(X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=torch.utils.data.DataLoader(train_dataset,batch_size=64,shuffle=True)\n",
    "test_loader=torch.utils.data.DataLoader(test_dataset,batch_size=64,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 104])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_size=64\n",
    "hidden_size=128\n",
    "\n",
    "\n",
    "class Ner_model(nn.Module):\n",
    "    def __init__(self,vocab_size,embedding_size,output_size,hidden_size):\n",
    "        super(Ner_model,self).__init__()\n",
    "        self.embedding=nn.Embedding(vocab_size,embedding_size,padding_idx=0)\n",
    "        self.rnn=nn.LSTM(embedding_size,hidden_size,num_layers=2,batch_first=True)\n",
    "        self.out=nn.Linear(hidden_size,output_size)\n",
    "    def forward(self,x):\n",
    "        x=self.embedding(x)\n",
    "        x,_=self.rnn(x)\n",
    "        x=self.out(x)\n",
    "        return x\n",
    "model=Ner_model(len(vocab),embedding_size,output_size=len(label_vocab),hidden_size=hidden_size)\n",
    "_,k=next(iter(train_loader))\n",
    "k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss=torch.nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from engine import train\n",
    "device=\"cuda\" if torch.cuda.is_available() else 'cpu'\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m result\u001b[38;5;241m=\u001b[39mtrain(model,train_loader,test_loader,optimizer,loss,\u001b[38;5;241m5\u001b[39m,device)\n",
      "File \u001b[1;32md:\\Study\\AI\\Code\\DL\\Name_entity_recog\\engine.py:159\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_dataloader, test_dataloader, optimizer, loss_fn, epochs, device)\u001b[0m\n\u001b[0;32m    152\u001b[0m results \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[0;32m    153\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_acc\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[0;32m    154\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[0;32m    155\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_acc\u001b[39m\u001b[38;5;124m\"\u001b[39m: []\n\u001b[0;32m    156\u001b[0m }\n\u001b[0;32m    158\u001b[0m \u001b[38;5;66;03m# Make sure model on target device\u001b[39;00m\n\u001b[1;32m--> 159\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m    161\u001b[0m \u001b[38;5;66;03m# Loop through training and testing steps for a number of epochs\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(epochs)):\n",
      "File \u001b[1;32mc:\\Users\\dungt\\anaconda3\\envs\\main\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1174\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1171\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1172\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m-> 1174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply(convert)\n",
      "File \u001b[1;32mc:\\Users\\dungt\\anaconda3\\envs\\main\\Lib\\site-packages\\torch\\nn\\modules\\module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 780\u001b[0m         module\u001b[38;5;241m.\u001b[39m_apply(fn)\n\u001b[0;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dungt\\anaconda3\\envs\\main\\Lib\\site-packages\\torch\\nn\\modules\\module.py:805\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    801\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    802\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    803\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 805\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m fn(param)\n\u001b[0;32m    806\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    808\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dungt\\anaconda3\\envs\\main\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1160\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   1153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m   1154\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[0;32m   1155\u001b[0m             device,\n\u001b[0;32m   1156\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1157\u001b[0m             non_blocking,\n\u001b[0;32m   1158\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[0;32m   1159\u001b[0m         )\n\u001b[1;32m-> 1160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[0;32m   1161\u001b[0m         device,\n\u001b[0;32m   1162\u001b[0m         dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1163\u001b[0m         non_blocking,\n\u001b[0;32m   1164\u001b[0m     )\n\u001b[0;32m   1165\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "result=train(model,train_loader,test_loader,optimizer,loss,5,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_single_sentence(vocab,z):\n",
    "    z,_=vectorized_sentence(vocab,z)\n",
    "    z=z[0]\n",
    "    new_z=torch.cat((z,torch.zeros(max_len-z.shape[0]))).type(torch.int64)\n",
    "    new_z=new_z.unsqueeze(0)\n",
    "    return new_z.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (1735618248.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[3], line 7\u001b[1;36m\u001b[0m\n\u001b[1;33m    if kq[i]!=0:\u001b[0m\n\u001b[1;37m                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "test=\"Iran hello European\"\n",
    "def predict(vocab,test):\n",
    "    hi=vectorize_single_sentence(vocab,test)\n",
    "    kq=model(hi)\n",
    "    kq.argmax(dim=1)\n",
    "    kq.squeeze(0)\n",
    "    kq_char=[]\n",
    "    for i in range(max_len):\n",
    "        if kq[i]!=0:\n",
    "            kq_char.append(tag_map[i])\n",
    "    return kq_char\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z=torch.tensor([1])\n",
    "k=z.item()\n",
    "type(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 5])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=nn.Embedding(10,5,padding_idx=0)\n",
    "k=torch.tensor([1,2,3,0,0,0])\n",
    "test(k).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lqd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
